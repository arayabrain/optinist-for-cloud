{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook was created to help users test and debug their own custom nodes. \n",
    "See [here](https://optinist.readthedocs.io/en/latest/specifications/add_algorithm.html) in the documentation for details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup:\n",
    "1. Create environment:\n",
    "    In terminal, run:\n",
    "    \n",
    "    `conda env create -n custom_node_test -f studio/app/optinist/wrappers/optinist/conda/optinist.yaml`\n",
    "\n",
    "    `conda activate custom_node_test`\n",
    "\n",
    "2. Install some additional packages:\n",
    "    We have included all of the packages for CaImAn, Suite2p and LCCD here, for easy combination of those \n",
    "    packages with your custom node. See the other notebooks for examples of how to use those packages. \n",
    "\n",
    "   `pip install pynwb imageio ipython jupyter notebook \"pydantic<2.0.0\" python-dotenv uvicorn xmltodict  bcrypt matplotlib \"scikit-learn==1.1.*\" plotly`\n",
    "  - If running in VS code, you may need to restart and/or select the correct environment with \"Python: Select Interpreter\"\n",
    "\n",
    "3. Run your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "\n",
    "from studio.app.dir_path import DIRPATH\n",
    "from studio.app.common.core.logger import AppLogger\n",
    "\n",
    "logger = AppLogger.get_logger()\n",
    "\n",
    "# Create input directories based on default saving path\n",
    "input_dir = os.path.join(DIRPATH.INPUT_DIR, \"1\")\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "unique_id = str(uuid.uuid4())[:8]  # Generate 8-char unique ID\n",
    "\n",
    "# Create output directory \n",
    "my_function_id = f\"my_func_{unique_id}\"\n",
    "my_output_dir = os.path.join(DIRPATH.OUTPUT_DIR, \"1\", unique_id, my_function_id)\n",
    "os.makedirs(my_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import OptiNiSt core data modules\n",
    "# Examples:\n",
    "from studio.app.optinist.core.nwb.nwb import NWBDATASET\n",
    "from studio.app.common.core.experiment.experiment import ExptOutputPathIds\n",
    "from studio.app.common.dataclass import CsvData, ImageData, TimeSeriesData, HTMLData\n",
    "from studio.app.optinist.dataclass import FluoData, BehaviorData, CaimanCnmfData, IscellData, LccdData, NWBFile, RoiData, SpikingActivityData, Suite2pData\n",
    "\n",
    "# Import ROI detection modules\n",
    "# Examples:\n",
    "# from studio.app.optinist.wrappers.suite2p import file_convert, registration, roi\n",
    "# from studio.app.optinist.wrappers.caiman import motion_correction, cnmf\n",
    "# from studio.app.optinist.wrappers.lccd import lccd_detection\n",
    "\n",
    "# Import OptiNiSt analysis modules\n",
    "# Examples:\n",
    "# from studio.app.optinist.wrappers.optinist.basic_neural_analysis.eta import ETA\n",
    "# from studio.app.optinist.wrappers.optinist.my_custom_node import MyCustomNode\n",
    "\n",
    "# Import OptiNiSt visualization modules\n",
    "# Examples:\n",
    "# from studio.app.common.dataclass import BarData, HeatMapData, HistogramData, ScatterData, LineData, PieData, PolarData, ScatterData\n",
    "from studio.app.common.dataclass import BarData, LineData\n",
    "\n",
    "# Import visualization modules\n",
    "# from caiman.utils.visualization import local_correlations\n",
    "# from plotly.subplots import make_subplots\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters. These should be saved in the folder XXXX\n",
    "my_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_analysis_function(\n",
    "    # Required inputs\n",
    "    neural_data: FluoData,  # Fluorescence data from previous processing\n",
    "    output_dir: str,        # Directory to save output files\n",
    "    # Optional inputs\n",
    "    iscell: IscellData = None,  # Cell classification data if needed\n",
    "    params: dict = None,        # Additional parameters to customize processing\n",
    "    **kwargs                    # Catch-all for additional arguments\n",
    ") -> dict:  # Function returns a dictionary containing all outputs\n",
    "    \"\"\"Example template for creating analysis functions.\n",
    "    \n",
    "    This function shows the basic structure for creating analysis functions\n",
    "    that work with the pipeline, including proper input handling, NWB file\n",
    "    creation, and return format.\n",
    "    \n",
    "    Args:\n",
    "        neural_data: Fluorescence data from previous processing steps\n",
    "        output_dir: Directory where output files should be saved\n",
    "        iscell: Optional cell classification data\n",
    "        params: Optional dictionary of parameters to customize processing\n",
    "        **kwargs: Additional keyword arguments\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing all output data and metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Set up logging if needed\n",
    "    logger.info(\"Starting my_analysis_function\")\n",
    "    \n",
    "    # 2. Get additional data from kwargs if needed\n",
    "    nwbfile = kwargs.get(\"nwbfile\", {})\n",
    "    \n",
    "    # 3. Set default parameters and update with user params\n",
    "    default_params = {\n",
    "        \"window_size\": 10,\n",
    "        \"threshold\": 0.5\n",
    "    }\n",
    "    if params is not None:\n",
    "        default_params.update(params)\n",
    "    \n",
    "    # 4. Main analysis code goes here\n",
    "    my_analysis = np.random.rand(10), np.random.rand(10)  # Example data\n",
    "\n",
    "    my_classification = my_analysis > default_params[\"threshold\"]\n",
    "    \n",
    "    # 5. Prepare NWB file structure\n",
    "    # Create a new NWB file dictionary or update existing one\n",
    "    nwb_output = {}\n",
    "    \n",
    "    # Add ROIs if your analysis creates them\n",
    "    nwb_output[NWBDATASET.ROI] = {} # List of ROI dictionaries\n",
    "    \n",
    "    # Add processing results\n",
    "    nwb_output[NWBDATASET.POSTPROCESS] = {\n",
    "        my_analysis: {\n",
    "            \"analysis_result\": my_analysis[0]  # Your analysis outputs\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Add column data (like classifications)\n",
    "    nwb_output[NWBDATASET.COLUMN] = {\n",
    "        my_classification: {\n",
    "            \"name\": \"my_classification\",\n",
    "            \"description\": \"Description of the classification\",\n",
    "            \"data\": my_analysis[1]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 6. Prepare return dictionary\n",
    "    # This should contain all outputs and processed data\n",
    "    info = {\n",
    "        # Analysis results in appropriate data containers\n",
    "        \"my_bar_data\": BarData(my_analysis[0], output_dir=output_dir, file_name=\"bar_data\"),\n",
    "        \"my_line_data\": LineData(my_analysis[1], output_dir=output_dir, file_name=\"line_data\"),\n",
    "        \n",
    "        # Add NWB file data\n",
    "        \"nwbfile\": nwb_output\n",
    "    }\n",
    "    \n",
    "    return info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suite2p_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
