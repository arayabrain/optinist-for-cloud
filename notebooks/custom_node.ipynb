{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook was created to help users test and debug their own custom nodes. \n",
    "This notebook will not add custom nodes to OptiNiSt. \n",
    "\n",
    "See [here](https://optinist.readthedocs.io/en/latest/specifications/add_algorithm.html) in the documentation for details on how to add your own custom nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup:\n",
    "1. Create environment:\n",
    "    In terminal, run:\n",
    "    \n",
    "    `conda env create -n custom_node_test -f studio/app/optinist/wrappers/optinist/conda/optinist.yaml`\n",
    "\n",
    "    `conda activate custom_node_test`\n",
    "\n",
    "2. Install some additional packages:\n",
    "    We have included all of the packages for CaImAn, Suite2p and LCCD here, for easy combination of those \n",
    "    packages with your custom node. See the other notebooks for examples of how to use those packages. \n",
    "\n",
    "   `pip install pynwb imageio ipython jupyter notebook \"pydantic<2.0.0\" python-dotenv uvicorn xmltodict  bcrypt matplotlib \"scikit-learn==1.1.*\" plotly`\n",
    "  - If running in VS code, you may need to restart and/or select the correct environment with \"Python: Select Interpreter\"\n",
    "\n",
    "3. Run your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "\n",
    "from studio.app.dir_path import DIRPATH\n",
    "from studio.app.common.core.logger import AppLogger\n",
    "\n",
    "logger = AppLogger.get_logger()\n",
    "\n",
    "# Create input directories based on default saving path\n",
    "input_dir = os.path.join(DIRPATH.INPUT_DIR, \"1\")\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "unique_id = str(uuid.uuid4())[:8]  # Generate 8-char unique ID\n",
    "\n",
    "# Create output directory \n",
    "my_function_id = f\"my_func_{unique_id}\"\n",
    "my_output_dir = os.path.join(DIRPATH.OUTPUT_DIR, \"1\", unique_id, my_function_id)\n",
    "os.makedirs(my_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Import standard libraries --\n",
    "import numpy as np\n",
    "# from typing import Dict, Literal, Union\n",
    "# import pandas as pd\n",
    "\n",
    "from studio.app.common.core.logger import AppLogger\n",
    "from studio.app.common.core.experiment.experiment import ExptOutputPathIds\n",
    "\n",
    "# -- Import OptiNiSt visualization modules --\n",
    "# Examples:\n",
    "# from studio.app.common.dataclass import BarData, HeatMapData,\n",
    "# HistogramData, ScatterData, LineData, PieData, PolarData, ScatterData\n",
    "from studio.app.common.dataclass import HeatMapData, ImageData\n",
    "\n",
    "# -- Import OptiNiSt core data modules --\n",
    "# Examples:\n",
    "from studio.app.optinist.core.nwb.nwb import NWBDATASET\n",
    "from studio.app.optinist.dataclass import FluoData\n",
    "\n",
    "# from studio.app.optinist.dataclass import FluoData, BehaviorData, CaimanCnmfData,\n",
    "# IscellData, LccdData, NWBFile, RoiData, SpikingActivityData, Suite2pData\n",
    "# from studio.app.common.core.experiment.experiment import ExptOutputPathIds\n",
    "\n",
    "# -- Import ROI detection modules --\n",
    "# Examples:\n",
    "# from studio.app.optinist.wrappers.suite2p import file_convert, registration, roi\n",
    "# from studio.app.optinist.wrappers.caiman import motion_correction, cnmf\n",
    "# from studio.app.optinist.wrappers.lccd import lccd_detection\n",
    "\n",
    "# -- Import OptiNiSt analysis modules --\n",
    "# Examples:\n",
    "# from studio.app.optinist.wrappers.optinist.basic_neural_analysis.eta import ETA\n",
    "# from studio.app.optinist.wrappers.optinist.my_custom_node import MyCustomNode\n",
    "\n",
    "# -- Import visualization modules --\n",
    "# from caiman.utils.visualization import local_correlations\n",
    "# from plotly.subplots import make_subplots\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters. These should be saved in the folder studio/app/optinist/wrappers/custom/params/custom_node.yaml\n",
    "my_params = {\"window_size\": 10, \"threshold\": 0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(\n",
    "    # Required inputs\n",
    "    input_data: ImageData,  # Fluorescence data from previous processing\n",
    "    output_dir: str,  # Directory to save output files\n",
    "    # Optional inputs\n",
    "    # iscell: IscellData = None,  # Cell classification data if needed\n",
    "    params: dict = None,  # Additional parameters to customize processing\n",
    "    **kwargs  # Catch-all for additional arguments\n",
    "    # Function returns a dictionary containing all outputs\n",
    ") -> dict(fluo=FluoData, image=ImageData, heatmap=HeatMapData):\n",
    "\n",
    "    \"\"\"Example template for creating analysis functions.\n",
    "\n",
    "    This function shows the basic structure for creating analysis functions\n",
    "    that work with the pipeline, including proper input handling, NWB file\n",
    "    creation, and return format.\n",
    "\n",
    "    Args:\n",
    "        neural_data: Fluorescence data from previous processing steps\n",
    "        output_dir: Directory where output files should be saved\n",
    "        iscell: Optional cell classification data\n",
    "        params: Optional dictionary of parameters to customize processing\n",
    "        **kwargs: Additional keyword arguments\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing all output data and metadata\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # 1. Set up logging if needed\n",
    "    logger = AppLogger.get_logger()\n",
    "    function_id = ExptOutputPathIds(output_dir).function_id # unique ID for each instance of function\n",
    "    logger.info(f\"start my_function: {function_id}\")\n",
    "\n",
    "    # 2. Get additional data from kwargs if needed\n",
    "    # nwbfile = kwargs.get(\"nwbfile\", {})\n",
    "\n",
    "    # 3. Set default parameters and update with user params\n",
    "    default_params = {\"window_size\": 10, \"threshold\": 0.5}\n",
    "    if params is not None:\n",
    "        default_params.update(params)\n",
    "\n",
    "    # 4. Main analysis code goes here\n",
    "    input_data = input_data.data\n",
    "\n",
    "    example_imaging_data_output = np.mean(input_data, axis=0)\n",
    "\n",
    "    example_fluo_data = input_data[:, 10:20, 100] # 10 \"ROI\" pixels \n",
    "\n",
    "    example_processing = example_fluo_data > default_params[\"threshold\"]\n",
    "\n",
    "    example_analysis = np.corrcoef(example_processing)\n",
    "    for i in range(example_analysis.shape[0]):\n",
    "        example_analysis[i, i] = np.nan\n",
    "\n",
    "    # 5. Prepare NWB file structure\n",
    "    # Create a new NWB file dictionary or update existing one\n",
    "    nwb_output = {}\n",
    "\n",
    "    # Add ROIs if your analysis creates them\n",
    "    nwb_output[NWBDATASET.ROI] = {}  # List of ROI dictionaries\n",
    "\n",
    "    # Example of adding processing results\n",
    "    nwb_output[NWBDATASET.POSTPROCESS] = {\n",
    "        \"analysis_result\": {  # Use a string as the key\n",
    "            \"data\": example_analysis[0]  # Your analysis outputs\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Example of data in column format (e.g. for classifications)\n",
    "    nwb_output[NWBDATASET.COLUMN] = {\n",
    "        \"my_classification\": {\n",
    "            \"name\": \"my_classification\",\n",
    "            \"description\": \"Description of the classification\",\n",
    "            \"data\": example_analysis[1],\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 6. Prepare return dictionary\n",
    "    # This should contain all outputs and processed data\n",
    "    info = {\n",
    "        \"fluo\": FluoData(example_fluo_data, file_name=\"fluo\"),\n",
    "        \"image\": ImageData(example_imaging_data_output, output_dir=output_dir, file_name=\"image\"),\n",
    "        \"heatmap\": HeatMapData(example_analysis, file_name=\"heatmap\"),\n",
    "    }\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = ImageData(np.random.rand(300, 512, 512), file_name=\"example_data\")\n",
    "my_function(input_data, \"my/path\", my_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suite2p_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
